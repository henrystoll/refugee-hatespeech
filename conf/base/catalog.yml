# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/data/data_catalog.html

<<<<<<< HEAD

raw_train_cad:
=======
####################### Raw Datasets ##########################
train_cad:
>>>>>>> 5954dc7b868f8e419c32aa5731f84837d215dcbd
  type: pandas.CSVDataSet
  filepath: data/01_raw/cad/cad_v1_1.tsv
  load_args:
    sep: '\t'
  layer: raw

raw_train_civil:
  type: pandas.CSVDataSet
  filepath: data/01_raw/civil/civil_comments_v2.csv
  layer: raw

raw_train_davidson:
  type: pandas.CSVDataSet
  filepath: data/01_raw/davidson/labeled_data.csv
  layer: raw

raw_train_dynhs:
  type: pandas.CSVDataSet
  filepath: data/01_raw/dynhs/dynhs-v0.2.3.csv
  layer: raw

raw_train_ghc:
  type: pandas.CSVDataSet
  filepath: data/01_raw/ghc/ghc_all.csv
  layer: raw

raw_train_hasoc:
  type: pandas.CSVDataSet
  filepath: data/01_raw/hasoc2019/hasoc2019_all.csv
  layer: raw

raw_train_hatemoji:
  type: pandas.CSVDataSet
  filepath: data/01_raw/hatemoji/HatemojiTrain.csv
  layer: raw

raw_train_hateval:
  type: pandas.CSVDataSet
  filepath: data/01_raw/hateval2019/hateval_AB_en.csv
  layer: raw

raw_train_hatexplain:
  type: pandas.CSVDataSet
  filepath: data/01_raw/hatexplain/data.csv
  layer: raw
  
raw_train_ousid:
  type: pandas.CSVDataSet
  filepath: data/01_raw/ousid/ousid_raw.csv
  layer: raw

raw_train_slur:
  type: pandas.CSVDataSet
  filepath: data/01_raw/slur/kurrek.2020.slur-corpus.csv
  layer: raw

raw_train_wiki:
  type: pandas.CSVDataSet
  filepath: data/01_raw/wikipedia/all-wikipedia.csv
  layer: raw

raw_hatecheck:
  type: pandas.CSVDataSet
  filepath: data/01_raw/hatecheck/test_suite_cases.csv
  load_args:
    sep: ';'
  layer: raw

raw_unhcr:
  type: pandas.ExcelDataSet
  filepath: data/01_raw/unhcr/refugee_data_unhcr.xlsx
  layer: raw

###################### Combined Dataset #######################

model_input_combined:
  type: pandas.ParquetDataSet
  filepath: data/03_primary/model_input_combined.pq
  layer: primary

###################### Training Datasets ######################

train_set:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/train_set.pq

training_set_oversampled:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/training_set_oversampled.pq

##################### Validation Datasets #####################

validation_set:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/validation_set.pq

######################## Test Datasets ########################

test_set:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/test_set.pq

test_hatecheck:
  type: pandas.ParquetDataSet
  filepath: data/03_primary/hatecheck.pq
  layer: primary

test_unhcr:
  type: pandas.ParquetDataSet
  filepath: data/03_primary/unhcr.pq
  layer: primary

##################### Prediction Datasets #####################

test_set_predictions:
  type: pandas.ParquetDataSet
<<<<<<< HEAD
  filepath: data/05_model_input/train_set.pq
  layer: model_input
=======
  filepath: data/07_model_output/test_set_predictions.pq
>>>>>>> 5954dc7b868f8e419c32aa5731f84837d215dcbd

hatecheck_predictions:
  type: pandas.ParquetDataSet
<<<<<<< HEAD
  filepath: data/05_model_input/validation_set.pq
  layer: model_input
=======
  filepath: data/07_model_output/hatecheck_predictions.pq
>>>>>>> 5954dc7b868f8e419c32aa5731f84837d215dcbd

unhcr_predictions:
  type: pandas.ParquetDataSet
<<<<<<< HEAD
  filepath: data/05_model_input/test_set.pq
  layer: model_input

train_set_oversampled:
  type: pandas.ParquetDataSet
  filepath: data/05_model_input/train_set_oversampled.pq
  layer: model_input
=======
  filepath: data/07_model_output/unhcr_predictions.pq








>>>>>>> 5954dc7b868f8e419c32aa5731f84837d215dcbd

